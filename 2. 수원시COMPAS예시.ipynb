{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoband.API import *\n",
    "# 버스정류장\n",
    "GetCompasData('SBJ_2102_002', '1', '1.수원시_버스정류장.csv')\n",
    "GetCompasData('SBJ_2102_002', '2', '2.수원시_버스정류장별_승하차이력(1).csv')\n",
    "GetCompasData('SBJ_2102_002', '3', '3.수원시_버스정류장별_승하차이력(2).csv')\n",
    "GetCompasData('SBJ_2102_002', '4', '4.수원시_버스정류장별_승하차이력(3).csv')\n",
    "GetCompasData('SBJ_2102_002', '5', '5.수원시_버스정류장별_승하차이력(4).csv')\n",
    "GetCompasData('SBJ_2102_002', '6', '6.수원시_버스정류장별_승하차이력(5).csv')\n",
    "GetCompasData('SBJ_2102_002', '7', '7.수원시_버스정류장별_노선현황.csv')\n",
    "\n",
    "# 지하철역\n",
    "GetCompasData('SBJ_2102_002', '8', '8.수원시_지하철역_위치정보.csv')\n",
    "GetCompasData('SBJ_2102_002', '9', '9.수원시_지하철역별_이용현황(2017~2019).csv')\n",
    "\n",
    "# 옥외광고물, 대기오염도, 주차장, 기상\n",
    "GetCompasData('SBJ_2102_002', '10', '10.수원시_옥외광고물현황.csv')\n",
    "GetCompasData('SBJ_2102_002', '11', '11.수원시_대기오염도_측정현황.csv')\n",
    "GetCompasData('SBJ_2102_002', '12', '12.수원시_주차장현황.csv')\n",
    "GetCompasData('SBJ_2102_002', '13', '13.수원시_기상데이터(2020).csv')\n",
    "\n",
    "# 유동인구\n",
    "GetCompasData('SBJ_2102_002', '14', '14.수원시_시간대별_유동인구(2020).csv')\n",
    "GetCompasData('SBJ_2102_002', '15', '15.수원시_성연령별_유동인구(2020).csv')\n",
    "GetCompasData('SBJ_2102_002', '16', '16.수원시_요일별_유동인구(2020).csv')\n",
    "\n",
    "# 인구정보\n",
    "GetCompasData('SBJ_2102_002', '17', '17.수원시_인구정보(고령)_격자.geojson')\n",
    "GetCompasData('SBJ_2102_002', '18', '18.수원시_인구정보(생산가능)_격자.geojson')\n",
    "GetCompasData('SBJ_2102_002', '19', '19.수원시_인구정보(유소년)_격자.geojson')\n",
    "\n",
    "# 교통량 & 혼잡강도\n",
    "GetCompasData('SBJ_2102_002', '20', '20.수원시_교통노드.geojson')\n",
    "GetCompasData('SBJ_2102_002', '21', '21.수원시_교통링크.geojson')\n",
    "GetCompasData('SBJ_2102_002', '22', '22.수원시_상세도로망_LV6.geojson')\n",
    "GetCompasData('SBJ_2102_002', '23', '23.수원시_평일_일별_시간대별_추정교통량_LV6.csv')\n",
    "GetCompasData('SBJ_2102_002', '24', '24.수원시_평일_일별_혼잡빈도강도_LV6.csv')\n",
    "GetCompasData('SBJ_2102_002', '25', '25.수원시_평일_일별_혼잡시간강도_LV6.csv')\n",
    "\n",
    "# 인도\n",
    "GetCompasData('SBJ_2102_002', '26', '26.수원시_인도(2017).geojson')\n",
    "\n",
    "# 건물\n",
    "GetCompasData('SBJ_2102_002', '27', '27.수원시_도로명주소(건물).geojson')\n",
    "GetCompasData('SBJ_2102_002', '28', '28.수`원시_건물연면적_격자.geojson')\n",
    "\n",
    "# 경계\n",
    "GetCompasData('SBJ_2102_002', '29', '29.수원시_법정경계(시군구).geojson')\n",
    "GetCompasData('SBJ_2102_002', '30', '30.수원시_법정경계(읍면동).geojson')\n",
    "GetCompasData('SBJ_2102_002', '31', '31.수원시_행정경계(읍면동).geojson')\n",
    "\n",
    "# 지적도\n",
    "GetCompasData('SBJ_2102_002', '32', '32.수원시_지적도.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# MCLP를 위한 선형계획법 툴\n",
    "from pulp import *\n",
    "\n",
    "# 시각화 툴 : Pydeck\n",
    "import pydeck as pdk\n",
    "\n",
    "# 지리 데이터 전처리 툴 : Shapely\n",
    "import shapely.speedups\n",
    "shapely.speedups.enable()\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point, MultiLineString, mapping, shape\n",
    "\n",
    "mapbox_key = 'pk.eyJ1IjoicWlxaTY1NCIsImEiOiJja2xnYW0xdWgyMmUyMnVxZWl2NGJpYng3In0.VIYWYBixklc-pAM9w7AjMA'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수원시 법정경계\n",
    "`base`는 모든 시각화에서 수원시 경계를 나타내는 데 사용될 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suwon = gpd.read_file('30.수원시_법정경계(읍면동).geojson')\n",
    "suwon['coordinates'] = suwon['geometry'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "suwon.head()\n",
    "\n",
    "# 수원 중심, 시각화에 사용될 예정\n",
    "center = [37.2737612, 126.9955691] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    suwon, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[255, 255, 255]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    "    opacity = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "`pydeck`은 geometry 타입을 받지 못하므로 인식가능한 형태로 변환이 필요하다.(`coordinates`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 건물 시각화\n",
    "### 정류장 주변의 취약계층 주요 이용시설(ex. 병원, 유치원 등)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 건물임에도 서로 다른 행에 존재해서 count할 때 중복되어 집계되므로\n",
    "# QGIS를 사용해 같은 지번, 건물타입을 갖는 건물을 하나의 건물로 묶음\n",
    "building_union = gpd.read_file('building_union.geojson')\n",
    "building_union['coordinates'] = building_union['geometry'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "building_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 정의서를 참고하여 정의한 \n",
    "# 취약계층 주요 이용시설건물코드, 미세먼지 유발시설 건물코드\n",
    "vulnerable_codes = ['03018', '03108', '07000', '07101', '07102', '07104', '07107', '07999', '08101', \n",
    "         '08102', '08103', '08201', '08202', '08203', '08204', '08299', '08300', '21003']\n",
    "dust_codes = ['06304', '06305', '13000', '13100', '13200', '16006', '19004', '18002', '18003']\n",
    "\n",
    "def func(x):\n",
    "    if x not in vulnerable_codes+dust_codes:\n",
    "        return 0\n",
    "    else:\n",
    "        return 200\n",
    "building_union['value'] = building_union['BDTYP_CD'].apply(lambda x: func(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화\n",
    "- 취약계층 주요 이용시설(Vulnerable_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    building_union[building_union['BDTYP_CD'].apply(lambda x: x in vulnerable_codes)] , # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    filled=True,\n",
    "    extruded=True,\n",
    "    wireframe=True,\n",
    "    get_fill_color='[0,255,0]',\n",
    "    get_elevation=\"value\",\n",
    "    pickable=True, auto_highlight=True\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    latitude=center[0], \n",
    "    longitude=center[1], \n",
    "    zoom=12,\n",
    "    pitch = 50\n",
    ") \n",
    "\n",
    "r = pdk.Deck(layers=[base, layer1], initial_view_state=view_state,\n",
    "             mapbox_key = 'pk.eyJ1IjoicWlxaTY1NCIsImEiOiJja2xnYW0xdWgyMmUyMnVxZWl2NGJpYng3In0.VIYWYBixklc-pAM9w7AjMA') \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 미세먼지 유발시설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    building_union[building_union['BDTYP_CD'].apply(lambda x: x in dust_codes)] , # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[0,255,0]',\n",
    "    filled=True,\n",
    "    extruded=True,\n",
    "    wireframe=True,\n",
    "    get_elevation=\"value\",\n",
    "    pickable=True, auto_highlight=True\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    latitude=center[0], \n",
    "    longitude=center[1], \n",
    "    zoom=12,\n",
    "    pitch = 50\n",
    ") \n",
    "\n",
    "r = pdk.Deck(layers=[base, layer2], initial_view_state=view_state,\n",
    "             mapbox_key = 'pk.eyJ1IjoicWlxaTY1NCIsImEiOiJja2xnYW0xdWgyMmUyMnVxZWl2NGJpYng3In0.VIYWYBixklc-pAM9w7AjMA') \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 성연령별 유동인구 시각화( 취약계층과 총 유동인구의 분포 비교)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gender = pd.read_csv('15.수원시_성연령별_유동인구(2020).csv').groupby(['lon', 'lat']).mean()\n",
    "pop_gender['TOTAL'] = pop_gender.sum(axis = 1)\n",
    "sns.heatmap(pop_gender.drop('STD_YM', axis=1).corr(),cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전 연령층 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 좌표 별 유동인구 합\n",
    "pop_gender = pd.read_csv('15.수원시_성연령별_유동인구(2020).csv')\n",
    "# 좌표별로 그룹화 진행 시간별로 더해줌\n",
    "pop_gender = pop_gender.groupby(['lon', 'lat']).sum() \n",
    "pop_gender = pop_gender.drop(['STD_YM'], axis = 1)\n",
    "# 모든 성연령별 유동인구 합계\n",
    "pop_gender['TOTAL'] = pop_gender.sum(axis = 1)\n",
    "pop_gender = pop_gender.reset_index()\n",
    "# df -> gdf\n",
    "pop_gender = gpd.GeoDataFrame(pop_gender, \n",
    "                              geometry=gpd.points_from_xy(pop_gender.lon, pop_gender.lat))\n",
    "pop_gender.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 취약계층(10대 미만, 60대 이상) 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 각 날짜별 10대인구, 60대 이상인구 각 좌표에서 시간별로 sum\n",
    "pop_gender_vul = pd.read_csv('15.수원시_성연령별_유동인구(2020).csv')[['WMAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_60GU',\n",
    "                                                            'MAN_FLOW_POP_CNT_10G','WMAN_FLOW_POP_CNT_10G','lon','lat','STD_YM']]\n",
    "pop_gender_vul = pop_gender_vul.groupby(['lon', 'lat']).sum()\n",
    "# 불필요한 column 제거\n",
    "pop_gender_vul = pop_gender_vul.drop(['STD_YM'], axis = 1)\n",
    "# 성별 관계없이 연령별로 합계\n",
    "pop_gender_vul['TOTAL_10'] = pop_gender_vul[['WMAN_FLOW_POP_CNT_10G','MAN_FLOW_POP_CNT_10G']].sum(axis = 1)\n",
    "pop_gender_vul['TOTAL_60'] = pop_gender_vul[['WMAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_60GU']].sum(axis = 1)\n",
    "\n",
    "# df -> gdf\n",
    "pop_gender_vul = pop_gender_vul.reset_index()\n",
    "pop_gender_vul = gpd.GeoDataFrame(pop_gender_vul, geometry=gpd.points_from_xy(pop_gender_vul.lon, pop_gender_vul.lat))\n",
    "pop_gender_vul = pop_gender_vul.drop(['WMAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_60GU',\n",
    "                                      'WMAN_FLOW_POP_CNT_10G','MAN_FLOW_POP_CNT_10G','lon', 'lat'], axis=1)\n",
    "pop_gender_vul['lon'] = pop_gender_vul['geometry'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "pop_gender_vul['lat'] = pop_gender_vul['geometry'].apply(lambda x : mapping(x)['coordinates'][1])\n",
    "pop_gender_vul['TOTAL_vul'] = pop_gender_vul[['TOTAL_10','TOTAL_60']].sum(axis = 1)\n",
    "pop_gender_vul['TOTAL'] = pop_gender['TOTAL']\n",
    "pop_gender_vul.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  #pop_gender_vul[pop_gender_vul['TOTAL_vul']> np.quantile(pop_gender_vul['TOTAL_vul'],0.8)][pop_gender_vul['TOTAL_vul']/pop_gender_vul['TOTAL'] > np.quantile(pop_gender_vul['TOTAL_vul']/pop_gender_vul['TOTAL'], 0.95)], \n",
    "                  pop_gender_vul[pop_gender_vul['TOTAL_vul'] > np.quantile(pop_gender_vul['TOTAL_vul'], 0.9)],\n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[255,0,0]',\n",
    "                  opacity = 0.05,\n",
    "                  get_radius=40,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat2 = pdk.Layer('ScatterplotLayer',\n",
    "                  pop_gender_vul[pop_gender['TOTAL'] > np.quantile(pop_gender['TOTAL'], 0.9)], \n",
    "                  get_position = ['lon','lat'],\n",
    "                  get_fill_color='[0,0,255]',\n",
    "                  get_radius=40,\n",
    "                  opacity = 0.1,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pdk.Deck(layers=[base, scat1, scat2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 시간대별 유동인구 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 유동인구 월별, 시간별 linePlot\n",
    "# 유동인구는 날짜에 큰 관계없이 시간별로 일정한 특징이 존재함\n",
    "pop_time = pd.read_csv('14.수원시_시간대별_유동인구(2020).csv')\n",
    "pop = pop_time.groupby(['STD_YM']).mean().reset_index()\n",
    "pop = pop.drop(['lon', 'lat'], axis=1)\n",
    "\n",
    "x = list(range(0,24))\n",
    "for i in range(len(pop)):\n",
    "    plt.plot(x, pop.iloc[i, 1:25].values)\n",
    "    \n",
    "plt.title('Population by time zone', fontsize=18) \n",
    "plt.ylabel('Population', fontsize=14)\n",
    "plt.xlabel('Time(Hour)', fontsize=14)\n",
    "plt.legend(list(map(lambda x: \"Month: \"+str(x), range(1,13))), loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 시간대별 분포를 확인하기 위해 좌표별로 평균을 구함\n",
    "test = pop_time.groupby(['lon','lat']).mean()\n",
    "test = test.drop(['STD_YM'], axis = 1).reset_index()\n",
    "test_lonlat = test[['lon', 'lat']]\n",
    "test = test.drop(['lon', 'lat'], axis=1)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구가 많은 지역을 파악하기 위해 70퍼센트 quantile 값으로 필터링\n",
    "# 시각화를 용이하게 하기위해 0부터 1까지의 값을 가지도록 스케일링\n",
    "# 이후에 지리적 차이를 확인하는 시각화에서 대부분 이와 같은 스케일링 과정을 거침 \n",
    "maximum = test.max().max()\n",
    "q70 = np.quantile(test,0.7)\n",
    "\n",
    "# 6시간 간격으로 유동인구의 변화를 확인\n",
    "test['TMST_06_reg'] = test['TMST_06']/maximum\n",
    "test['TMST_12_reg'] = test['TMST_12']/maximum\n",
    "test['TMST_18_reg'] = test['TMST_18']/maximum\n",
    "test['TMST_00_reg'] = test['TMST_00']/maximum\n",
    "\n",
    "test = pd.concat([test, test_lonlat], axis=1)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  test[test['TMST_06']>q70], \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,5000*TMST_06_reg,200]',\n",
    "                  get_radius=40,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "scat2 = pdk.Layer('ScatterplotLayer',\n",
    "                  test[test['TMST_12']>q70], \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,5000*TMST_12_reg,200]',\n",
    "                  get_radius=40,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "scat3 = pdk.Layer('ScatterplotLayer',\n",
    "                  test[test['TMST_18']>q70], \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,5000*TMST_18_reg,200]',\n",
    "                  get_radius=40,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "scat4 = pdk.Layer('ScatterplotLayer',\n",
    "                  test[test['TMST_00']>q70], \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,5000*TMST_00_reg,200]',\n",
    "                  get_radius=40,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=10\n",
    ") \n",
    "\n",
    "### 06시 유동인구 시각화\n",
    "r = pdk.Deck(layers=[base,scat1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 12시 유동인구 시각화\n",
    "r = pdk.Deck(layers=[base,scat2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 18시 유동인구 시각화\n",
    "r = pdk.Deck(layers=[base,scat3], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 00시 유동인구 시각화\n",
    "r = pdk.Deck(layers=[base,scat4], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 시간대별 상세 도로의 추정 교통량 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간대별 교통량\n",
    "traffic = pd.read_csv('23.수원시_평일_일별_시간대별_추정교통량_LV6.csv')\n",
    "traffic = traffic.rename(columns = {'상세도로망_LinkID' : 'link_id'})\n",
    "\n",
    "# 추정교통량의 link_id는 상행/하행정보를 포함하고 있어 매핑이 되지 않으므로 분리해줌\n",
    "traffic['link_id'] = traffic['link_id'].apply(lambda x : str(x))\n",
    "traffic['상행하행'] = traffic['link_id'].apply(lambda x: x[-2:])\n",
    "traffic['link_id'] = traffic['link_id'].apply(lambda x: x[:-2])\n",
    "\n",
    "# 하루동안의 교통량의 분포를 파악하기 위해 fulltime 분리\n",
    "traffic_fulltime = traffic[traffic['시간적범위'] == 'fulltime']\n",
    "network = gpd.read_file('22.수원시_상세도로망_LV6.geojson')\n",
    "traffic_fulltime['link_id'] = traffic_fulltime['link_id'].apply(lambda x : str(x))\n",
    "traffic_fulltime = traffic_fulltime.merge(network, on =['link_id'], how='left')\n",
    "traffic_fulltime['전체_추정교통량_reg'] = traffic_fulltime['전체_추정교통량']/traffic_fulltime['전체_추정교통량'].max()\n",
    "traffic_fulltime['coordinates'] = traffic_fulltime['geometry'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "\n",
    "traffic_ver1 = traffic[traffic['시간적범위'] != 'fulltime']\n",
    "\n",
    "traffic_ver1['시간적범위'] = traffic_ver1['시간적범위'].apply(lambda x : int(x))\n",
    "traffic_mean = traffic_ver1.groupby(['시간적범위']).mean()\n",
    "traffic_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(traffic_mean.index.values, traffic_mean.전체_추정교통량.values, color='green')\n",
    "    \n",
    "plt.title('Traffic by time zone', fontsize=18) \n",
    "plt.ylabel('Traffic', fontsize=14)\n",
    "plt.xlabel('Time(Hour)', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 교통량과 상세도로망, link_id 기준으로 병합\n",
    "network = gpd.read_file('22.수원시_상세도로망_LV6.geojson')\n",
    "traffic_ver2 = traffic_ver1.merge(network, on =['link_id'], how='left')\n",
    "traffic_ver2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p70 = np.percentile(traffic_ver2['전체_추정교통량'], 70)\n",
    "\n",
    "traffic_ver2['전체_추정교통량_reg'] = traffic_ver2['전체_추정교통량'].apply(lambda x: x/p70 if x<=p70 else 1)\n",
    "traffic_ver2['coordinates'] = traffic_ver2['geometry'].apply(lambda x : mapping(x)['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_00 = traffic_ver2[traffic_ver2['시간적범위']==0]\n",
    "traffic_06 = traffic_ver2[traffic_ver2['시간적범위']==6]\n",
    "traffic_12 = traffic_ver2[traffic_ver2['시간적범위']==12]\n",
    "traffic_18 = traffic_ver2[traffic_ver2['시간적범위']==18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 00시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = pdk.Layer( 'PathLayer', \n",
    "                  traffic_00, \n",
    "                  get_path='coordinates', \n",
    "                  get_width='전체_추정교통량/50', \n",
    "                  get_color='[255,255*전체_추정교통량_reg,120]', \n",
    "                  pickable=True, auto_highlight=True \n",
    "                 )\n",
    "layer2 = pdk.Layer( 'PathLayer', \n",
    "                  traffic_06, \n",
    "                  get_path='coordinates', \n",
    "                  get_width='전체_추정교통량/50', \n",
    "                  get_color='[255,255*전체_추정교통량_reg,120]', \n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "layer3 = pdk.Layer( 'PathLayer', \n",
    "                  traffic_12, \n",
    "                  get_path='coordinates', \n",
    "                  get_width='전체_추정교통량/50', \n",
    "                  get_color='[255,255*전체_추정교통량_reg,120]', \n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "layer4 = pdk.Layer( 'PathLayer', \n",
    "                  traffic_18, \n",
    "                  get_path='coordinates', \n",
    "                  get_width='전체_추정교통량/50', \n",
    "                  get_color='[255,255*전체_추정교통량_reg,120]', \n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=10\n",
    ") \n",
    "r = pdk.Deck(layers=[base, layer1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 06시 교통량 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pdk.Deck(layers=[base, layer2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 12시 교통량 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pdk.Deck(layers=[base, layer3], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 18시 교통량 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pdk.Deck(layers=[base, layer4], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 대기오염도(미세먼지) - 미세먼지 대체 변수로 활용하기 위한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "air = pd.read_csv('11.수원시_대기오염도_측정현황.csv')\n",
    "air = air.rename(columns = {'미세먼지(㎍/㎥)' : '미세먼지', '초미세먼지(㎍/㎥)' : '초미세먼지','오존(ppm)':'오존',\n",
    "                            '이산화질소(ppm)': '이산화질소', '아황산가스(ppm)' : '아황산가스', '일산화탄소(ppm)' : '일산화탄소'})\n",
    "air = air[air['미세먼지'] != '-'] #결측값 제거\n",
    "air['미세먼지'] = air['미세먼지'].apply(pd.to_numeric)\n",
    "air['초미세먼지'] = air['초미세먼지'].apply(pd.to_numeric)\n",
    "\n",
    "# 오염물질 측정단위 통일\n",
    "air['오존'] = air['오존'].apply(pd.to_numeric)*(48/22.4)*1000\n",
    "air['이산화질소'] = air['이산화질소'].apply(pd.to_numeric)*(46.0055/22.4)*1000\n",
    "air['아황산가스'] = air['아황산가스'].apply(pd.to_numeric)*(64.006/22.4)*1000\n",
    "air['일산화탄소'] = air['일산화탄소'].apply(pd.to_numeric)*(28.01/22.4)*1000\n",
    "\n",
    "# 스케일링 진행, anova 테스트에는 영향을 주지 않음\n",
    "dust = ['미세먼지', '초미세먼지', '오존', '이산화질소', '아황산가스', '일산화탄소']\n",
    "scaler = StandardScaler()\n",
    "air[dust] = scaler.fit_transform(air[dust])\n",
    "\n",
    "air.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# anova\n",
    "for d in dust:\n",
    "    g1, g2, g3, g4, g5, g6, g7, g8 = [air[air['측정소']==a][d].values for a in air.측정소.unique()]\n",
    "    F_statistic, pVal = stats.f_oneway(g1, g2, g3, g4, g5, g6, g7, g8)\n",
    "    if pVal < 0.05:\n",
    "        print(f\"<{d}> F-value : {round(F_statistic, 3)}, p-value : {round(pVal,3)} ***\")\n",
    "    else:\n",
    "        print(f\"<{d}> F-value : {round(F_statistic, 3)}, p-value : {round(pVal,3)}\")\n",
    "\n",
    "# 일산화탄소와 이산화질소 : 귀무가설 기각    \n",
    "# 일산화탄소와 이산화질소의 주 배출원은 자동차(도로이동오염원)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air = air.groupby(['측정소']).mean()\n",
    "air['coordinates'] = list(zip(air.lon, air.lat))\n",
    "air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air['dust_이산화질소'] = air['이산화질소'] - air['이산화질소'].min()/(air['이산화질소'].max() - air['이산화질소'].min())\n",
    "air['dust_일산화탄소'] = air['이산화질소'] - air['이산화질소'].min()/(air['이산화질소'].max() - air['이산화질소'].min())\n",
    "air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = pdk.Layer( 'PathLayer', \n",
    "                  traffic_fulltime, \n",
    "                  get_path='coordinates', \n",
    "                  get_width='전체_추정교통량/150', \n",
    "                  get_color='[255,255*전체_추정교통량_reg,120]', \n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "scat1 = pdk.Layer(\n",
    "    \"ScatterplotLayer\",\n",
    "    air,\n",
    "    get_position = ['lon','lat'],\n",
    "    get_color = '[255,255,255]',\n",
    "    get_fill_color = '[0,500*dust_이산화질소,255]',\n",
    "    get_radius= 200,\n",
    "    pickable=True, auto_highlight=True\n",
    ")\n",
    "\n",
    "scat2 = pdk.Layer(\n",
    "    \"ScatterplotLayer\",\n",
    "    air,\n",
    "    get_position = ['lon','lat'],\n",
    "    get_color = '[255,255,255]',\n",
    "    get_fill_color = '[0,500*dust_일산화탄소,255]',\n",
    "    get_radius= 200,\n",
    "    pickable=True, auto_highlight=True\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=10\n",
    ") \n",
    "\n",
    "#view_state.bearing = -15\n",
    "#view_state.pitch = 45\n",
    "\n",
    "r = pdk.Deck(layers=[base,layer, scat1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pdk.Deck(layers=[base,layer, scat2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링을 위한 전처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인도 폭 & 버스 정류장 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiLineString, mapping, shape\n",
    "\n",
    "india = gpd.read_file('26.수원시_인도(2017).geojson')\n",
    "india['coordinates'] = india['geometry'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "\n",
    "india['WIDT_reg'] = india['WIDT'] / india['WIDT'].max() # 시각화를 위한 정규화\n",
    "india.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화\n",
    "- 버스정류장과 인도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_raw = pd.read_csv('1.수원시_버스정류장.csv')\n",
    "\n",
    "layer1 = pdk.Layer( 'PathLayer', \n",
    "                  india, \n",
    "                  get_path='coordinates', \n",
    "                  get_color='[255,165,0]', \n",
    "                  width_min_pixels=2,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  station_raw, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_color = '[255,255,255]',\n",
    "                  get_fill_color='[102,160,145]',\n",
    "                  get_radius=40,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, layer1, scat1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버스정류장 전처리\n",
    "- QGIS를 이용해 정류장(`1.수원시_버스정류장.csv`)과 그것에 최근접한 인도(`26.수원시_인도(2017).geojson`)를 매핑 후 `read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 1179개의 버스정류장\n",
    "station = pd.read_csv('station_sidewalk.csv').iloc[:, :-6]\n",
    "station = station.drop(['UFID', 'QUAL', \"BYYN\", 'KIND','쉘터','LED',\n",
    "                        'LCD','LED+LCD복합형', '알뜰형','임대형(음성)'], axis=1)\n",
    "\n",
    "# 인도폭이 4m 이상(최소 보도폭 : 1.5m + 스마트 버스정류장의 세로길이 : 2.5m)\n",
    "station = station[station['WIDT'] >= 4]\n",
    "\n",
    "# BIS가 설치된 곳은 전기/통신 설비를 갖춤\n",
    "station= station.dropna(subset = ['BIS설치여부'])\n",
    "print(station.shape)\n",
    "station.rename(columns = {'정류장ID':'정류소ID'}, inplace=True)\n",
    "station.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수원시의 버스정류장, 인도폭과 BIT설치여부로 필터링된 정류장(분석대상) 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  station_raw, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[102,160,145]',\n",
    "                  get_radius=50,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "scat2 = pdk.Layer('ScatterplotLayer',\n",
    "                  station, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[152,255,152]',\n",
    "                  get_radius=120,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat1, scat2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 승하차 이력 합치기\n",
    "- 정류소별 전체 승차 건수 & 환승 건수 & 전체 하차 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['2.수원시_버스정류장별_승하차이력(1).csv', '3.수원시_버스정류장별_승하차이력(2).csv', '4.수원시_버스정류장별_승하차이력(3).csv', \n",
    "          '5.수원시_버스정류장별_승하차이력(4).csv', '6.수원시_버스정류장별_승하차이력(5).csv']\n",
    "\n",
    "df = pd.concat([pd.read_csv(d) for d in data])\n",
    "\n",
    "# 환승 건수는 전체 승차 건수에 포함되어 있음\n",
    "# 각 정류소의 일별 승, 하차 평균\n",
    "on_off = df.groupby(['정류소ID'])[['전체 승차 건수','환승 건수', '전체 하차 건수']].mean()\n",
    "on_off.reset_index(inplace = True)\n",
    "# bus_station과 인덱스 명을 맞춰줌\n",
    "#on_off = on_off.rename(columns = {'정류소ID' : '정류장ID'})\n",
    "on_off.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정류소별 운행하는 버스 종류에 따라 평균 승차인원\n",
    "bus_route = df[['정류소ID','노선번호', '노선유형','전체 승차 건수']]\n",
    "bus_route['노선번호'] = bus_route['노선번호'].apply(lambda x: str(x).replace('_','-'))\n",
    "bus_route['노선번호'] = bus_route['노선번호'].apply(lambda x: str(x).replace('예약',''))\n",
    "\n",
    "bus_route = bus_route.groupby(['정류소ID', '노선유형'])['전체 승차 건수'].mean()\n",
    "bus_route = bus_route.unstack(fill_value = 0)\n",
    "\n",
    "# 맞춤형시내버스 == 따복형시내버스\n",
    "bus_route_list = ['경기외곽순환버스', '광역급행형시내버스', '따복형시내버스',\n",
    "                  '일반형시내버스','좌석형시내버스', '직행좌석형시내버스']\n",
    "bus_route.columns = bus_route_list\n",
    "bus_route = bus_route.reset_index()\n",
    "bus_route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스정류장에 승하차, 노선 정보 병합\n",
    "station_1 = station.merge(on_off, on='정류소ID', how='left')\n",
    "station_ver1 = station_1.merge(bus_route, on = '정류소ID', how='left').fillna(0)\n",
    "station_ver1 = gpd.GeoDataFrame(station_ver1, geometry=gpd.points_from_xy(station_ver1.lon, station_ver1.lat))\n",
    "station_ver1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버스 노선별 배차간격 (공공데이터 포털 API 이용)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import json\n",
    "from urllib import parse, request\n",
    "\n",
    "station_raw = pd.read_csv('1.수원시_버스정류장.csv')\n",
    "station_raw.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수원시의 정류장을 지나다니는 모든 노선의 ID를 추출\n",
    "- 버스 도착 시간 정보 API : 입력 값 : 정류장 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://openapi.gbis.go.kr/ws/rest/busarrivalservice/station'\n",
    "API_KEY = 'xDCJxBLtrjyz7m6c+/BAENwUEKfqE5/nlSnSeyutrm/P8jezX9lpPg2Ej9iemgcMcy9sNtA91wxnSsqmc1Mx6A=='\n",
    "\n",
    "routeid_list = set()\n",
    "\n",
    "for station_id in tqdm(list(map(str, station_raw['정류장ID'].values))):\n",
    "    queryParams = '?' + parse.urlencode({ parse.quote_plus('ServiceKey') : API_KEY, parse.quote_plus('serviceKey') : '1234567890', parse.quote_plus('stationId') : station_id })\n",
    "\n",
    "    requests = request.Request(url + queryParams)\n",
    "    requests.get_method = lambda: 'GET'\n",
    "    response_body = request.urlopen(requests).read()\n",
    "\n",
    "    result = xmltodict.parse(response_body)\n",
    "    stationid_info = json.loads(json.dumps(result))\n",
    "    \n",
    "    try:\n",
    "        routeid = pd.DataFrame(stationid_info['response']['msgBody']['busArrivalList'])['routeId']\n",
    "        routeid_list.update(routeid.values)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "# 5개만 랜덤하게 추출해서 확인\n",
    "set(random.sample(routeid_list, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추출한 노선의 ID를 추출하여 그 값을 입력값으로 하여 노선유형별 배차간격 추출\n",
    "- 버스 노선 정보 API : 입력값 : 노선ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "url = 'http://openapi.gbis.go.kr/ws/rest/busrouteservice/info'\n",
    "API_KEY = 'xDCJxBLtrjyz7m6c+/BAENwUEKfqE5/nlSnSeyutrm/P8jezX9lpPg2Ej9iemgcMcy9sNtA91wxnSsqmc1Mx6A=='\n",
    "route_dict = dict()\n",
    "\n",
    "for rooteid in tqdm(routeid_list):\n",
    "    temp = url + '?ServiceKey=' + API_KEY + '&serviceKey=1234567890&routeId=' + rooteid\n",
    "\n",
    "    requests = request.Request(temp)\n",
    "    requests.get_method = lambda: 'GET'\n",
    "    response_body = request.urlopen(requests).read()\n",
    "    result_1 = xmltodict.parse(response_body)\n",
    "    routeId_info = json.loads(json.dumps(result_1))\n",
    "    try:\n",
    "        route_type = routeId_info['response']['msgBody']['busRouteInfoItem']['routeTypeName']\n",
    "        min_interval = routeId_info['response']['msgBody']['busRouteInfoItem']['peekAlloc']\n",
    "        max_interval = routeId_info['response']['msgBody']['busRouteInfoItem']['nPeekAlloc']\n",
    "        route_dict[rooteid] = [route_type, np.mean([int(min_interval), int(max_interval)])]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_interval = pd.DataFrame(route_dict).transpose()\n",
    "route_interval.columns = ['노선유형', '배차시간']\n",
    "route_interval = route_interval[route_interval['노선유형'] != '일반형 공항버스']\n",
    "route_interval = route_interval[route_interval['노선유형'] != '리무진형 공항버스']\n",
    "route_interval = route_interval[route_interval['노선유형'] != '일반형시외버스']\n",
    "\n",
    "route_interval['배차시간'] = route_interval['배차시간'].apply(pd.to_numeric)\n",
    "route_interval  = route_interval[route_interval['배차시간'] < 60] # 이상치 제거\n",
    "\n",
    "wait_time = route_interval.groupby(['노선유형']).median()/2\n",
    "wait_time = wait_time.reset_index()\n",
    "\n",
    "wait_time.rename(columns = {'배차시간': '대기시간'}, inplace = True)\n",
    "wait_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API에 따라 결과가 계속 바뀌어서 2021.03.28 시점 기준으로 데이터 저장\n",
    "#wait_time.to_csv('wait_time.csv', index=False)\n",
    "wait_time = pd.DataFrame({'노선유형':['경기외곽순환버스', '광역급행형시내버스','따복형시내버스',\n",
    "                                 '일반형시내버스','좌석형시내버스','직행좌석형시내버스'],\n",
    "                        '대기시간':[27.5 ,9.375 ,27.5 ,8 , 5.5, 10.625]})\n",
    "wait_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | 노선유형 | 대기시간|\n",
    "|---|---|---|\n",
    "| 0 | 경기외곽순환버스 | 27.500 |\n",
    "| 1 | 광역급행형시내버스 | 9.375 |\n",
    "| 2 | 따복형시내버스 | 27.500 |\n",
    "| 3 | 일반형시내버스 | 8.000 |\n",
    "| 4 | 좌석형시내버스 | 5.500 |\n",
    "| 5 | 직행좌석형시내버스 | 10.625 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스유형마다 각 유형에 해당하는 대기시간을 곱해줌\n",
    "for route_type, val in wait_time.values:\n",
    "    if route_type not in bus_route_list:\n",
    "        val = np.mean(wait_time.대기시간)\n",
    "    station_ver1[route_type] = station_ver1[route_type] * val\n",
    "\n",
    "# type_list\n",
    "type_list = wait_time.노선유형.values\n",
    "\n",
    "station_ver1['총대기시간'] = station_ver1[type_list].sum(axis=1)\n",
    "station_ver1.drop(bus_route_list, axis=1, inplace=True)\n",
    "station_ver1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정류장 버퍼 폴리곤 생성\n",
    "정류장을 중심으로 radius meter만큼 반지름을 갖는 원 폴리곤\n",
    "<br>`정류소별 영향권 및 접근거리를 반영한 버스 통행배정 신뢰성 향상 방안 연구`에 따라 버스 정류장의 영향권은 400m로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radius : 미터\n",
    "def make_circle_polygon(gdf, radius = 400):\n",
    "    \n",
    "    gdf.crs = 'epsg:4326'\n",
    "    gdf = gdf.to_crs(epsg=5179) \n",
    "\n",
    "    buffer = gdf.buffer(radius)\n",
    "    gdf['BUFFER'] = buffer.to_crs(epsg=4326)\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    return gdf\n",
    "    \n",
    "station_ver1 = make_circle_polygon(station_ver1)\n",
    "station_ver1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ver1['coordinates'] = station_ver1['BUFFER'].apply(lambda x : mapping(x)['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    station_ver1, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[0, 0, 0]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    "    opacity = 0.1\n",
    ")\n",
    "\n",
    "scat = pdk.Layer('ScatterplotLayer',\n",
    "                  station_ver1, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,255,0]',\n",
    "                  get_radius ='70',\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=10\n",
    ") \n",
    "r = pdk.Deck(layers=[base, layer, scat], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 건물 전처리\n",
    "### 정류장 주변의 취약계층 주요 이용시설(ex. 병원) & 정류장 주변의 미세먼지 발생 시설\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 건물임에도 서로 다른 행에 존재해서 count할 때 중복되어 집계되므로\n",
    "# QGIS를 사용해 같은 지번, 건물타입을 갖는 건물을 하나의 건물로 묶음\n",
    "from shapely.ops import unary_union\n",
    "building_union = gpd.read_file('building_union.geojson')\n",
    "building_union['coordinates'] = building_union['geometry'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "building_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정류장 버퍼 내에 취약계층이 주로 이용하는 시설과 미세먼지를 유발하는 시설의 수를 얻는다.\n",
    "vulnerable_codes = ['03018', '03108', '07000', '07101', '07102', '07104', '07107', '07999', '08101', \n",
    "         '08102', '08103', '08201', '08202', '08203', '08204', '08299', '08300', '21003']\n",
    "\n",
    "# {col}값이 {code}와 같은 {df}의 행들 중에서, {poly}와 겹치는 행(시설)의 개수 반환\n",
    "def intersect_buffer(df, col ,code, poly):\n",
    "    df = df[df[col] == code]\n",
    "    in_out = df.intersects(poly)\n",
    "    within_buffer = df[in_out]\n",
    "    return len(within_buffer)\n",
    "\n",
    "# 반복문을 돌며 {_codes}에 포함되는 시설 개수를 표시하는 칼럼 추가\n",
    "print('-----취약계층-----')\n",
    "for c in vulnerable_codes:\n",
    "    print(f'{c}가 처리되는중..')\n",
    "    station_ver1[c] = station_ver1['BUFFER'].apply(lambda x: intersect_buffer(building_union, 'BDTYP_CD', c, x))\n",
    "\n",
    "vulnerable_dict = { '03018' : '조산원', '03108' : '보건소', '07000' : '의료시설', '07101' : '종합병원',\n",
    "                   '07102' : '산부인과병원', '07104' : '한방병원', '07107' : '병원', '07999' : '기타의료시설',\n",
    "                   '08101' : '초등학교', '08102' : '중학교', '08103' : '고등학교', '08201' : '유치원',\n",
    "                   '08202' : '영유아보육시설' , '08203' : '어린이집', '08204' : '아동복지시설',\n",
    "                   '08299' : '기타아동관련시설', '08300' : '노인복지시설', '21003' : '어린이회관'}    \n",
    "station_ver1 = station_ver1.rename(columns = vulnerable_dict)\n",
    "\n",
    "\n",
    "dust_codes = ['06304', '06305', '13000', '13100', '13200', '16006', '19004', '18002', '18003', '19004']\n",
    "\n",
    "print('----미세먼지유발----')\n",
    "for c in dust_codes:\n",
    "    print(f'{c}가 처리되는중..')\n",
    "    station_ver1[c] = station_ver1['BUFFER'].apply(lambda x: intersect_buffer(building_union, 'BDTYP_CD', c, x))\n",
    "\n",
    "dust_dict = { '06304' : '화물터미널', '06305' : '철도역사', '13000' : '공장', '13100' : '일반공장',\n",
    "            '13200' : '공해공장', '16006' : '정비공장', '19004' : '발전소', '18002' : '폐기물처리시설','18003' : '폐기물재활용시설'}\n",
    "station_ver2 = station_ver1.rename(columns = dust_dict)\n",
    "station_ver2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    station_ver1, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[0, 0, 0]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    "    opacity = 0.1\n",
    ")\n",
    "\n",
    "scat = pdk.Layer('ScatterplotLayer',\n",
    "                  station_ver2, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,255,0]',\n",
    "                  get_radius ='70',\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "layer1 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    building_union[building_union['BDTYP_CD'].apply(lambda x: x in vulnerable_codes)] , # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[200, 0, 0]',\n",
    "    pickable=True, auto_highlight=True\n",
    ")\n",
    "\n",
    "layer2 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    building_union[building_union['BDTYP_CD'].apply(lambda x: x in dust_codes)] , # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[0, 0, 200]',\n",
    "    pickable=True, auto_highlight=True\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=12\n",
    ") \n",
    "r = pdk.Deck(layers=[base, layer, scat, layer1, layer2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_ver3 = station_ver2.drop(list(station_ver2.iloc[:,-27:].columns), axis=1)\n",
    "station_ver3['취약계층건물'] = station_ver2[vulnerable_dict.values()].sum(axis=1)\n",
    "station_ver3['먼지유발건물'] = station_ver2[dust_dict.values()].sum(axis=1)\n",
    "station_ver3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성연령별 유동인구 전처리\n",
    "-  취약 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 위도 경도 위치 기준으로 있는 각 날짜별 인구수 sum\n",
    "pop_gender_vul = pd.read_csv('15.수원시_성연령별_유동인구(2020).csv')[['WMAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_10G','WMAN_FLOW_POP_CNT_10G','lon','lat','STD_YM']].groupby(['lon', 'lat']).sum()\n",
    "# 불필요한 column 제거\n",
    "pop_gender_vul = pop_gender_vul.drop(['STD_YM'], axis = 1)\n",
    "# 동일한 위도 경도 위치에 있는 취약 계층 빈도를 sum\n",
    "pop_gender_vul['TOTAL_10'] = pop_gender_vul[['WMAN_FLOW_POP_CNT_10G','MAN_FLOW_POP_CNT_10G']].sum(axis = 1)\n",
    "pop_gender_vul['TOTAL_60'] = pop_gender_vul[['WMAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_60GU']].sum(axis = 1)\n",
    "pop_gender_vul = pop_gender_vul.reset_index()\n",
    "\n",
    "pop_gender_vul = gpd.GeoDataFrame(pop_gender_vul, geometry=gpd.points_from_xy(pop_gender_vul.lon, pop_gender_vul.lat))\n",
    "pop_gender_vul = pop_gender_vul.drop(['WMAN_FLOW_POP_CNT_60GU','MAN_FLOW_POP_CNT_60GU',\n",
    "                                      'WMAN_FLOW_POP_CNT_10G','MAN_FLOW_POP_CNT_10G','lon', 'lat'], axis=1)\n",
    "pop_gender_vul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gender_vul['lon'] = pop_gender_vul.geometry.x\n",
    "pop_gender_vul['lat'] = pop_gender_vul.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    station_ver1, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[0, 0, 0]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    "    opacity = 0.1\n",
    ")\n",
    "\n",
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  station_ver1, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,255,0]',\n",
    "                  get_radius ='70',\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "scat2 = pdk.Layer('ScatterplotLayer',\n",
    "                  pop_gender_vul, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[170, 249, 209]',\n",
    "                  get_radius ='10',\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=12\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat2, layer, scat1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반경 내에 취약계층(10대, 60대) 유동인구 평균 추가\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def pop_within_buffer(df, column, poly):\n",
    "    in_out = df.within(poly)\n",
    "    within_buffer = df[in_out]\n",
    "    return np.mean(within_buffer[column])\n",
    "\n",
    "station_ver3['POP_10'] = station_ver3['BUFFER'].apply(lambda x: pop_within_buffer(pop_gender_vul, 'TOTAL_10', x))\n",
    "station_ver3['POP_60'] = station_ver3['BUFFER'].apply(lambda x: pop_within_buffer(pop_gender_vul, 'TOTAL_60', x))\n",
    "station_ver3['POP_vul'] = station_ver3['POP_10'] + station_ver3['POP_60']\n",
    "station_ver3.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간(날짜별) 데이터를 위도 경도를 기준으로 각 타겟 인구수의 평균을 구했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시간대별 유동인구 X 시간대별 통행량 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 좌표별 시간대별 유동인구\n",
    "pop_time = pd.read_csv('14.수원시_시간대별_유동인구(2020).csv')\n",
    "pop_time = pop_time.groupby(['lon','lat']).mean().drop(['STD_YM'], axis=1)\n",
    "pop_time = pop_time.reset_index()\n",
    "\n",
    "pop_time = gpd.GeoDataFrame(pop_time, geometry=gpd.points_from_xy(pop_time.lon, pop_time.lat))\n",
    "#pop_time = pop_time.drop(['lon','lat'],axis=1)\n",
    "\n",
    "print(pop_time.shape)\n",
    "pop_time.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정류장 주변으로 빈틈이 없도록 사각형 버퍼 생성\n",
    "def make_square_polygon(gdf, radius = 25):\n",
    "    \n",
    "    gdf.crs = 'epsg:4326'\n",
    "    gdf = gdf.to_crs(epsg=5179)\n",
    "\n",
    "    buffer = gdf.buffer(radius, cap_style=3)\n",
    "    gdf['BUFFER'] = buffer.to_crs(epsg=4326)\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    return gdf\n",
    "\n",
    "pop_time = make_square_polygon(pop_time)\n",
    "pop_time.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_time['coordinates'] = pop_time['BUFFER'].apply(lambda x : mapping(x)['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    pop_time, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[255, 255, 255]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    "    opacity = 0.7\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    latitude=center[0], \n",
    "    longitude=center[1], \n",
    "    zoom=11\n",
    ") \n",
    "\n",
    "r = pdk.Deck(layers=[base, layer1], initial_view_state=view_state,\n",
    "            mapbox_key = 'pk.eyJ1IjoicWlxaTY1NCIsImEiOiJja2xnYW0xdWgyMmUyMnVxZWl2NGJpYng3In0.VIYWYBixklc-pAM9w7AjMA') \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = pd.read_csv('23.수원시_평일_일별_시간대별_추정교통량_LV6.csv')\n",
    "traffic = traffic.rename(columns = {'상세도로망_LinkID' : 'link_id', '전체_추정교통량':'추정교통량'})\n",
    "traffic = traffic[['link_id','시간적범위','추정교통량']]\n",
    "\n",
    "# 시간적범위 칼럼 데이터타입 통일\n",
    "traffic = traffic[traffic['시간적범위'] != 'fulltime']\n",
    "traffic['시간적범위'] = traffic['시간적범위'].apply(pd.to_numeric)\n",
    "traffic = pd.pivot_table(traffic, index=['link_id'], columns=['시간적범위'], values=['추정교통량'])\n",
    "traffic.columns = list(range(0,24))\n",
    "traffic = traffic.reset_index()\n",
    "\n",
    "traffic['link_id'] = traffic['link_id'].apply(lambda x: int(str(x)[:-2]))\n",
    "traffic.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = gpd.read_file('22.수원시_상세도로망_LV6.geojson')\n",
    "network['link_id'] = network['link_id'].apply(pd.to_numeric)\n",
    "traffic_network = traffic.merge(network, on =['link_id'], how='left')\n",
    "traffic_network = traffic_network.iloc[:,list(range(1,25))+[-1]]\n",
    "traffic_network = gpd.GeoDataFrame(traffic_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구와 통행량이 미치는 영향 차이가 크지 않도록 스케일링\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Scaler = MinMaxScaler()\n",
    "pop_time.iloc[:,2:26] = Scaler.fit_transform(pop_time.iloc[:,2:26])\n",
    "\n",
    "Scaler = MinMaxScaler()\n",
    "traffic_network[list(range(0,24))] = Scaler.fit_transform(traffic_network[list(range(0,24))])\n",
    "traffic_network.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도로에 근접한 gird만 추출\n",
    "inter = []\n",
    "for i,x in pop_time.iterrows():\n",
    "    intersected = traffic_network.intersects(x.BUFFER)\n",
    "    temp = traffic_network[intersected]\n",
    "    if len(temp) == 0:\n",
    "        inter.append(False)\n",
    "    else:\n",
    "        inter.append(True)\n",
    "    if i % 10000 == 0:\n",
    "        print(\"loading..\")\n",
    "    \n",
    "pop_time['INTERSECTED'] = inter\n",
    "pop_time_inter = pop_time[pop_time['INTERSECTED']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 되었나 확인\n",
    "layer1 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    pop_time_inter, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[255, 255, 255]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    "    opacity = 0.7\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    latitude=center[0], \n",
    "    longitude=center[1], \n",
    "    zoom=11\n",
    ") \n",
    "\n",
    "r = pdk.Deck(layers=[base, layer1], initial_view_state=view_state,\n",
    "            mapbox_key = 'pk.eyJ1IjoicWlxaTY1NCIsImEiOiJja2xnYW0xdWgyMmUyMnVxZWl2NGJpYng3In0.VIYWYBixklc-pAM9w7AjMA') \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_product = []\n",
    "for i,x in pop_time_inter.iterrows():\n",
    "    intersected = traffic_network.intersects(x.BUFFER)\n",
    "    temp = traffic_network[intersected]\n",
    "    v1 = x[2:26].values\n",
    "    v2 = temp[list(range(0,24))].mean(axis=0).values\n",
    "    sum_product.append(np.sum(v1*v2))\n",
    "    if i % 3000 == 0:\n",
    "        print(\"loading..\")\n",
    "    \n",
    "pop_time_inter['POPxTRAFFIC'] = sum_product\n",
    "pop_time_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p90 = np.percentile(pop_time_inter['POPxTRAFFIC'], 90)\n",
    "m = pop_time_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_time_inter['reg'] = pop_time_inter['POPxTRAFFIC'].apply(lambda x: x/p90 if x<=p90 else 1)\n",
    "pop_time_inter['coordinates'] = pop_time_inter['BUFFER'].apply(lambda x : mapping(x)['coordinates'][0])\n",
    "pop_time_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = pdk.Layer(\n",
    "    'PolygonLayer', # 사용할 Layer 타입\n",
    "    pop_time_inter, # 시각화에 쓰일 데이터프레임\n",
    "    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름\n",
    "    get_fill_color='[0, 255*reg, 0]' # 각 데이터 별 rgb 또는 rgba 값 (0~255)\n",
    ")\n",
    "\n",
    "center = center\n",
    "view_state = pdk.ViewState( \n",
    "    latitude=center[0], \n",
    "    longitude=center[1],\n",
    "    zoom=11\n",
    ") \n",
    "\n",
    "#view_state.bearing = -15\n",
    "#view_state.pitch = 45\n",
    "\n",
    "r = pdk.Deck(layers=[base,layer1], initial_view_state=view_state,\n",
    "            mapbox_key = mapbox_key) \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_traffic = pop_time_inter[['POPxTRAFFIC','geometry']]\n",
    "print(pop_traffic.shape)\n",
    "pop_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_traffic.to_csv('pop_traffic_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터링에 사용할 데이터\n",
    "data = station_ver3[['정류소ID','lon','lat','geometry','BUFFER','총대기시간','POP_vul','먼지유발건물','취약계층건물']]\n",
    "train_data_1 = data[['POP_vul','총대기시간','먼지유발건물','취약계층건물']]\n",
    "train_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "def visualize_silhouette(cluster_lists, X_features,a): \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산.\n",
    "        if a == 'kmeans' :\n",
    "            clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state = 0)\n",
    "        elif a == 'spectral' :\n",
    "            clusterer = SpectralClustering(n_clusters = n_cluster, random_state = 0)\n",
    "        elif a == 'agg' :\n",
    "            clusterer = AgglomerativeClustering(n_clusters = n_cluster)\n",
    "        elif a == 'gmm' :\n",
    "            clusterer = GaussianMixture(n_components = n_cluster, random_state = 0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(a)\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_1 = StandardScaler()\n",
    "scale_1.fit(train_data_1)\n",
    "train_data_scaled_1 = scale_1.transform(train_data_1)\n",
    "train_data_1[list(train_data_1.columns)] = train_data_scaled_1\n",
    "train_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster 개수를 2개, 3개, 4개, 5개 일때의 클러스터별 실루엣 계수 평균값을 시각화 \n",
    "#visualize_silhouette([2,3,4,5,6], train_data_1)\n",
    "visualize_silhouette([4,5,6,7,8], train_data_1,'kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['KMEANS'] =  KMeans(n_clusters = 4, init = 'k-means++', max_iter = 100, random_state = 0).fit_predict(train_data_1)\n",
    "test = data.groupby(['KMEANS']).mean()\n",
    "score_kmeans = np.zeros(len(test))\n",
    "for i in list(train_data_1.columns) :\n",
    "    score_kmeans += ss.rankdata(test[i])\n",
    "score_kmeans = pd.Series(score_kmeans).sort_values()\n",
    "print('---스코어---')\n",
    "print(score_kmeans)\n",
    "print('--군집별 정류장 개수--')\n",
    "print(data['KMEANS'].value_counts())\n",
    "drop_kmeans = list(score_kmeans.index[:2])\n",
    "print('--제거할 군집--')\n",
    "print(drop_kmeans)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Spectral'] = SpectralClustering(n_clusters = 7, random_state = 0).fit_predict(train_data_1)\n",
    "test = data.groupby(['Spectral']).mean()\n",
    "score_spectral = np.zeros(len(test))\n",
    "for i in list(train_data_1.columns) :\n",
    "    score_spectral += ss.rankdata(test[i])\n",
    "score_spectral = pd.Series(score_spectral)\n",
    "print('---스코어---')\n",
    "print(score_spectral.sort_values())\n",
    "print('--군집별 정류장 개수--')\n",
    "print(data['Spectral'].value_counts())\n",
    "# 0과 6중 스코어가 동일하므로 다른 클러스터링과의 공통부분 결합을 위해 6를 직접 지정\n",
    "#drop_spectral = list(score_spectral.sort_values().index[:2])\n",
    "print('--제거할 군집--')\n",
    "drop_spectral = [2,6]\n",
    "print(drop_spectral)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Agg'] =  AgglomerativeClustering(n_clusters = 5).fit_predict(train_data_1)\n",
    "test = data.groupby(['Agg']).mean()\n",
    "score_agg = np.zeros(len(test))\n",
    "for i in list(train_data_1.columns) :\n",
    "    score_agg += ss.rankdata(test[i])\n",
    "score_agg = pd.Series(score_agg)\n",
    "print('---스코어---')\n",
    "print(score_agg.sort_values())\n",
    "print('--군집별 정류장 개수--')\n",
    "print(data['Agg'].value_counts())\n",
    "drop_agg = list(score_agg.sort_values().index[:2])\n",
    "print(drop_agg)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['GMM'] = GaussianMixture(n_components = 5, random_state = 0).fit_predict(train_data_1)\n",
    "test = data.groupby(['GMM']).mean()\n",
    "score_GMM = np.zeros(len(test))\n",
    "for i in list(train_data_1.columns) :\n",
    "    score_GMM += ss.rankdata(test[i])\n",
    "score_GMM = pd.Series(score_GMM)\n",
    "print('---스코어---')\n",
    "print(score_GMM.sort_values())\n",
    "print('--군집별 정류장 개수--')\n",
    "print(data['GMM'].value_counts())\n",
    "drop_GMM = list(score_GMM.sort_values().index[:2])\n",
    "print(drop_GMM)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 클러스터링 알고리즘의 군집 결과에서 공통 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data = data[np.array(data.KMEANS != drop_kmeans[0]) & np.array(data.KMEANS != drop_kmeans[1])\n",
    "    & np.array(data.GMM != drop_GMM[0]) & np.array(data.GMM != drop_GMM[1])\n",
    "    & np.array(data.Spectral != drop_spectral[0]) & np.array(data.Spectral != drop_spectral[1])\n",
    "    & np.array(data.Agg != drop_agg[0]) & np.array(data.Agg != drop_agg[1])]\n",
    "len(clustered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  clustered_data, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,160,0]',\n",
    "                  get_radius=100,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "# [100,255*전체 승차 건수_reg,100]\n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat1], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_traffic = pd.read_csv('pop_traffic_final.csv')\n",
    "pop_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = clustered_data\n",
    "station = station[['정류소ID','lon', 'lat', 'geometry']]\n",
    "station = gpd.GeoDataFrame(station, geometry=gpd.points_from_xy(station.lon, station.lat))\n",
    "#station['dv'] = ['y[%s]'%s for s in station.정류소ID ]\n",
    "station = station.reset_index()\n",
    "station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(pop_traffic.geometry, gpd.geoseries.GeoSeries):\n",
    "    pop_traffic['lon'] = pop_traffic['geometry'].apply(lambda x: x[7:-1].split(' ')[0])\n",
    "    pop_traffic['lat'] = pop_traffic['geometry'].apply(lambda x: x[7:-1].split(' ')[1])\n",
    "    pop_traffic =  gpd.GeoDataFrame(pop_traffic, geometry=gpd.points_from_xy(pop_traffic.lon, pop_traffic.lat))\n",
    "    pop_traffic = pop_traffic.drop(['lon','lat'], axis=1)\n",
    "pop_traffic.reset_index(inplace=True)\n",
    "pop_traffic = pop_traffic.rename(columns = {'POPxTRAFFIC' : 'weights'})\n",
    "pop_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_traffic.crs = 'epsg:4326'\n",
    "station.crs = 'epsg:4326'\n",
    "\n",
    "pop_traffic = pop_traffic.to_crs(epsg=5179) \n",
    "station = station.to_crs(epsg=5179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 정류장과 기준 좌표들 간의 거리 행렬\n",
    "d = np.empty((len(pop_traffic), len(station)))\n",
    "for i in range(len(pop_traffic)):\n",
    "    point_i = pop_traffic.geometry[i]\n",
    "    d[i] = [point_i.distance(point_j) for point_j in station.geometry]\n",
    "    if i % 2000 == 0:\n",
    "        print('loading'+ '.'*(i//2000)+ '_'*(6-i//2000))\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정류장사이의 거리\n",
    "# 정류장 간에 최소 거리가 어느 정도 이상이어야 한다는 제약조건을 반영하기 위함.\n",
    "r = np.empty((len(station), len(station)))\n",
    "for i in range(len(station)):\n",
    "    station_i = station.geometry[i]\n",
    "    r[i] = [ station_i.distance(station_j) for station_j in station.geometry]\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = pop_traffic.index.values\n",
    "J = station.index.values\n",
    "S = 400\n",
    "min_dist = 50\n",
    "\n",
    "a = pop_traffic.weights.values\n",
    "P = 30\n",
    "\n",
    "# Compute the sets Ni\n",
    "# NB: this will be a list in which each item is a list of nodes\n",
    "# within the threshold distance of the i'th node\n",
    "N = [[j for j in J if d[i][j] < S] for i in I]\n",
    "R = [[int(r[station_i][station_j] < min_dist) for station_j in J ] for station_i in J]\n",
    "# Formulate optimisation\n",
    "\n",
    "prob = LpProblem(\"MCLP\", LpMaximize)\n",
    "x = LpVariable.dicts(\"x\", J, lowBound=0, upBound=1, cat='Integer')\n",
    "y = LpVariable.dicts(\"y\", I, lowBound=0, upBound=1, cat='Integer')\n",
    "\n",
    "# Objective\n",
    "prob += lpSum([a[i]*y[i] for i in I])\n",
    "\n",
    "# Constraints\n",
    "for i in I:\n",
    "    prob += lpSum([x[j] for j in N[i]]) >= y[i]\n",
    "for j in J:\n",
    "    prob += lpSum([x[rr] for rr in R[j]]) <= 1\n",
    "    \n",
    "\n",
    "prob += lpSum([x[j] for j in J]) == P\n",
    "\n",
    "# Solve problem\n",
    "prob.solve()\n",
    "\n",
    "x_soln = np.array([x[j].varValue for j in J])\n",
    "\n",
    "# And print some output\n",
    "print ((\"Status:\"), LpStatus[prob.status])\n",
    "print (\"Weight Covered is = \", value(prob.objective))\n",
    "print (\"x = \", x_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station['opt'] = x_soln\n",
    "station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_id = station[station['opt'] == 1]['정류소ID'].values\n",
    "station_raw = pd.read_csv('1.수원시_버스정류장.csv')\n",
    "station_raw['optimal'] = station_raw['정류장ID'].apply(lambda x: x in opt_id)\n",
    "station_raw[station_raw['optimal'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat1 = pdk.Layer('ScatterplotLayer',\n",
    "                  station_raw[station_raw['optimal']==0], \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[0,255,0]',\n",
    "                  get_radius=50,\n",
    "                  opacity = 0.1,\n",
    "                  pickable=True, auto_highlight=True\n",
    "                 ) \n",
    "\n",
    "scat2 = pdk.Layer('ScatterplotLayer',\n",
    "                  station_raw[station_raw['optimal']==1], \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[127,255,212]',\n",
    "                  get_radius=200,\n",
    "                  pickable=True, auto_highlight=True \n",
    "                 ) \n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat1, scat2], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선정 결과에서 접근성 및 편의성 확인\n",
    "- 지하철역의 위치정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway = pd.read_csv('8.수원시_지하철역_위치정보.csv')\n",
    "subway = subway.rename(columns = {'역사명':'역명', '노선명':'호선명'})\n",
    "subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_dict = {'랜드마크':['광교호수공원', '국토지리정보원지도박물관','만석공원','방화수류정',\n",
    "                        '화성행궁', '서호공원', '광교저수지쉼터', '롯데백화점 수원점',\n",
    "                        'NC백화점 수원터미널점', 'AK플라자 수원점', '갤러리아백화점 광교'],\n",
    "                'lon':[127.0637281,127.0529836, 126.9989156, 127.015922,\n",
    "                      127.0115454,126.9882966,127.0105735,126.9950386,\n",
    "                      127.0180337,126.9981621,127.0527941],\n",
    "                'lat':[37.283123, 37.2761374, 37.3007055,37.2875274,\n",
    "                      37.281962,37.2803729,37.3068497,37.264328,\n",
    "                      37.2500302,37.2654804,37.2805385]}\n",
    "landmark = pd.DataFrame(landmark_dict)\n",
    "landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat3 = pdk.Layer('ScatterplotLayer',\n",
    "                  subway, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[255,100,0]',\n",
    "                  get_radius=150,\n",
    "                  pickable=True, auto_highlight=True\n",
    "                 ) \n",
    "\n",
    "scat4 = pdk.Layer('ScatterplotLayer',\n",
    "                  landmark, \n",
    "                  get_position = ['lon','lat'], \n",
    "                  get_fill_color='[255,255,0]',\n",
    "                  get_radius=150,\n",
    "                  pickable=True, auto_highlight=True\n",
    "                 )  \n",
    "\n",
    "center = center \n",
    "view_state = pdk.ViewState( \n",
    "    longitude=center[1], \n",
    "    latitude=center[0], \n",
    "    zoom=11\n",
    ") \n",
    "r = pdk.Deck(layers=[base, scat1, scat2, scat3, scat4], initial_view_state=view_state,\n",
    "            mapbox_key = \"pk.eyJ1IjoiamFzb243NjU1IiwiYSI6ImNrbTF6ODV2ajBubHgydm05Y2dsZmhnbXoifQ.HqZQtFRrorSuizkwe6kpFg\") \n",
    "r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 입지선정 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop_gender.drop(['lon','lat','TOTAL'], axis=1)\n",
    "column_list = [f'{age}대 남성' for age in range(10, 60, 10)] + ['60대 이상 남성'] \n",
    "column_list += [f'{age}대 여성 ' for age in range(10, 60, 10)] + ['60대 이상 여성'] \n",
    "pop.columns = column_list + ['geometry']\n",
    "pop.crs = 'epsg:4326'\n",
    "pop.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.92/0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문 \"광고유형 및 성별에 따른 광고효과와 정서반응 패턴, 정은경 외, 2012\"에 따르면 여성은 약 1.2배 더 큰 광고 효과를 가짐\n",
    "for col in [f'{age}대 여성 ' for age in range(10, 60, 10)] + ['60대 이상 여성']:\n",
    "    pop[col] = pop[col]*(0.92/0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ver4 = station_ver3[['정류소ID', '정류장명','lon','lat','BUFFER']]\n",
    "station_ver4['optimal'] = station_ver4['정류소ID'].apply(lambda x: x in opt_id)\n",
    "station_ver4 = station_ver4[station_ver4['optimal'] == True]\n",
    "\n",
    "for col in tqdm(column_list):\n",
    "    station_ver4[col] = station_ver4['BUFFER'].apply(lambda x: pop_within_buffer(pop, col, x))\n",
    "station_ver4.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#광고 타겟층 선정\n",
    "advertise_target = []\n",
    "for i in range(len(station_ver4)):\n",
    "    target_list = station_ver4[column_list].iloc[i,:]\n",
    "    advertise_target.append(target_list.idxmax())\n",
    "    \n",
    "station_ver4['광고 Target층'] = advertise_target\n",
    "station_final = station_ver4.drop(['optimal'] + column_list, axis=1)\n",
    "station_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_traffic = pd.read_csv('pop_traffic_final.csv')\n",
    "\n",
    "if not isinstance(pop_traffic.geometry, gpd.geoseries.GeoSeries):\n",
    "    pop_traffic['lon'] = pop_traffic['geometry'].apply(lambda x: x[7:-1].split(' ')[0])\n",
    "    pop_traffic['lat'] = pop_traffic['geometry'].apply(lambda x: x[7:-1].split(' ')[1])\n",
    "    pop_traffic =  gpd.GeoDataFrame(pop_traffic, geometry=gpd.points_from_xy(pop_traffic.lon, pop_traffic.lat))\n",
    "    pop_traffic = pop_traffic.drop(['lon','lat'], axis=1)\n",
    "pop_traffic.reset_index(inplace=True)\n",
    "pop_traffic.crs = 'epsg:4326'\n",
    "pop_traffic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선정된 POP x TRAFFIC 기준으로 순위 산정\n",
    "station_final['order'] = station_final['BUFFER'].apply(lambda x: pop_within_buffer(pop_traffic, 'POPxTRAFFIC', x))\n",
    "station_final = station_final.sort_values(['order'],ascending= False).reset_index()\n",
    "station_final = station_final.drop(['BUFFER','order'], axis=1)\n",
    "\n",
    "station_final['index'] = range(1, 31)\n",
    "station_final.rename(columns = {'정류소ID':'정류장ID','index' : '설치순위', 'lon':'X축좌표(경도)', 'lat':'Y축좌표(위도)'}, inplace = True)\n",
    "station_final = station_final[['설치순위','정류장명','정류장ID','X축좌표(경도)','Y축좌표(위도)','광고 Target층']]\n",
    "station_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_final.to_csv('분석결과_수타버스.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잡동사니"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 취약계층(인구정보)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "older = gpd.read_file('17.수원시_인구정보(고령)_격자.geojson')\n",
    "older['geometry'] = older['geometry'].apply(lambda x: x.centroid)\n",
    "older.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반경 내에 취약계층(older) 평균 추가\n",
    "import shapely.speedups\n",
    "shapely.speedups.enable()\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def pop_within_buffer(df, column, poly):\n",
    "    in_out = df.within(poly)\n",
    "    within_buffer = df[in_out]\n",
    "    return np.mean(within_buffer[column])\n",
    "\n",
    "station_ver1['older'] = station_ver1['BUFFER'].apply(lambda x: pop_within_buffer(older, 'val', x))\n",
    "station_ver1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유소년에 대해서도 똑같이 해줌\n",
    "youth = gpd.read_file('19.수원시_인구정보(유소년)_격자.geojson')\n",
    "youth['geometry'] = youth['geometry'].apply(lambda x: x.centroid)\n",
    "\n",
    "station_1['youth'] = station_1['youth'].apply(lambda x: pop_within_buffer(youth, 'val', x))\n",
    "station_1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
